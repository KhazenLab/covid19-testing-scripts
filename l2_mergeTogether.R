# -*- coding: utf-8 -*-
"""t11c-shadi-merge with confirmed cases and population.r.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CWQSSWWuPG-k2REyVfgBZyebQvyVsp2o
"""

"""## Load confirmed cases"""

library(data.table)
library(zoo)

# Load dataset
# augmentedData_fn = "covid19-global-forecasting-week-2.v20200330.augmented.RData"
augmentedData_fn = "covid19-global-forecasting-week-4.v20200408.augmented.RData"
augmentedData_url = "https://biominers-b1.s3.eu-west-3.amazonaws.com/kaggle-covid19-global-forecasting-week-1-c6t77usW/%s"
augmentedData_url = sprintf(augmentedData_url, augmentedData_fn)
if(!file.exists(augmentedData_fn)) {
  download.file(augmentedData_url, augmentedData_fn)
}
augmented_data = readRDS(augmentedData_fn)

conf_train = data.table(augmented_data$l2_clean$train)

#Combine country and province into a single string
conf_train$CountryProv = ifelse(
                                # is.na(conf_train$Province_State),
                                as.character(conf_train$Province_State)=="",
                                as.character(conf_train$Country_Region),
                                paste(as.character(conf_train$Country_Region),
                                      as.character(conf_train$Province_State), sep=" – ")
                                )

# drop the lat/long and pick it up again later from the country_metadata file
conf_train$Lat = NULL
conf_train$Long = NULL

"""## Load total tests

Manually upload the file ~~~`gdrive/biominers/shadi/multiple-aggregated_owid_wiki_worldometers-v20200406.csv`~~~

`gdrive/biominers/shadi/multiple-aggregated_owid_wiki_worldometers-gitrepo.csv` to this colab instance

(because R notebooks do not support mounting the google drive)
"""

dir_gitrepo = "/content/covid19-testing"

# totaltests_fn = "multiple-aggregated_owid_wiki_worldometers_biominers-v20200406.csv"
totaltests_fn = "multiple-aggregated_owid_wiki_worldometers_biominers-gitrepo.csv"
totaltests_fn = sprintf("%s/%s", dir_gitrepo, totaltests_fn)

stopifnot(file.exists(totaltests_fn))
totaltests_data = read.csv(totaltests_fn, stringsAsFactors=F)
totaltests_data$Date = as.Date(totaltests_data$Date)

# sort
totaltests_data = totaltests_data[with(totaltests_data, order(Location, Date)),]

# name corrections
totaltests_data$Location[ totaltests_data$Location=="Aruba" ] = "Netherlands – Aruba"
totaltests_data$Location[ totaltests_data$Location=="Cayman Islands" ] = "United Kingdom – Cayman Islands"
totaltests_data$Location[ totaltests_data$Location=="Mayotte" ] = "France – Mayotte"
totaltests_data$Location[ totaltests_data$Location=="South Korea" ] = "Korea, South"
totaltests_data$Location[ totaltests_data$Location=="Taiwan" ] = "Taiwan*"
totaltests_data$Location[ totaltests_data$Location=="Bosnia" ] = "Bosnia and Herzegovina"
totaltests_data$Location[ totaltests_data$Location=="Bermuda" ] = "United Kingdom – Bermuda"
totaltests_data$Location[ totaltests_data$Location=="Brunei " ] = "Brunei"
totaltests_data$Location[ totaltests_data$Location=="Greenland" ] = "Denmark – Greenland"

# drop dupes
totaltests_data = totaltests_data[!duplicated(totaltests_data[,c("Location","Date")]),]

# Need to drop dupes
# dim(totaltests_data) # 1485
# dim(unique(totaltests_data[,c("Location","Date")])) # 1431
stopifnot(   sum(duplicated(totaltests_data[,c("Location","Date")]))==0  )
# totaltests_data[ duplicated(totaltests_data[,c("Location","Date")]), ]


"""## Merge together total tests with confirmed cases"""


# "Aruba" %in% conf_train$CountryProv
# conf_train$CountryProv[grepl("Greenland", conf_train$CountryProv)]
totaltests_data$Location[grepl("Kuwait", totaltests_data$Location)]

conf_train = merge(conf_train,
                   totaltests_data,
                   by.x=c("CountryProv","Date"),
                   by.y=c("Location","Date"),
                   all.x=T, all.y=F, sort=F
                   )

setkeyv(conf_train, c("CountryProv","Date"))


"""## Add population

Manually download

~~~`gdrive/Halim/Datasets/confirmed+population_v20200408.csv`~~~

~~~`gdrive/shadi/totaltests/t11c-population.csv`~~~

`gitlab.com/biominers/covid19-testing/t11c-country_metadata.csv`

and upload to colab instance
"""

#df_pop = read.csv("confirmed+population_v20200408.csv", stringsAsFactors=F)
#df_pop = unique(df_pop[,c("Country_Region", "Province_State","Population")])
#df_pop$CountryProv = with(df_pop,
#                          ifelse(Province_State=="",
#                                 Country_Region,
#                                 sprintf("%s – %s", Country_Region, Province_State)
#                                 ))
#dim(df_pop)

# save to csv
# write.csv(df_pop, "t11c-population.csv", row.names=F)

countrymeta_fn = "t11c-country_metadata.csv"
countrymeta_fn = sprintf("%s/%s", dir_gitrepo, countrymeta_fn)
df_pop = read.csv(countrymeta_fn, stringsAsFactors=F)


conf_train = merge(conf_train,
                   df_pop[,c("CountryProv", "Population", "Lat", "Long")],
                   by="CountryProv",
                   all.x=T, all.y=F, sort=F
                 )

"""## Count per source of total tests"""

# entries from biominers
# sum(is.na(conf_train$total_cumul.all)) - sum(conf_train$total_cumul.source=="biominers", na.rm=T)
# sum(conf_train$total_cumul.source=="biominers", na.rm=T)

df_counts = table(ifelse(is.na(conf_train$total_cumul.source),"NA", conf_train$total_cumul.source))

# save the counts
save_fn2 = "t11c-sourceCounts.csv"
save_fn2 = sprintf("%s/%s", dir_gitrepo, save_fn2)
# Use na="" since arcgis.com doesn't support values for NAs
# write.csv(conf_train, "t11c-confirmed+totalTests-v20200406-historical.csv")
write.csv(df_counts, save_fn2, na="", row.names=F,quote=F)





"""## supplementary stat: tests per mil"""

conf_train$tests_per_mil = with(conf_train, floor(total_cumul.all	/ Population * 1e6))

# bring back the same order as earlier versions
colOrder = c(
  "CountryProv", "Date", "Country_Region", "Province_State", "Id", "ConfirmedCases",
  "Fatalities", "Lat", "Long", "Lat_Long", "is_validation",
  "total_cumul.all", "total_cumul.source", "Population", "tests_per_mil"
)


conf_train = conf_train[,..colOrder]


"""## Supplementary stats

- Tests per million
- positive/negative splits
- percentage confirmed of total
"""

# Fix some outliers where total tests < confirmed cases
conf_train$total_cumul.all	= with(conf_train, pmax(total_cumul.all, ConfirmedCases))

conf_train$ratio_confirmed_total_pct = with(conf_train, ConfirmedCases/total_cumul.all*100)
conf_train$negative_cases = with(conf_train, total_cumul.all - ConfirmedCases)

# check missing Lat/Long
stopifnot( !any(is.na(conf_train$Lat )) )
stopifnot( !any(is.na(conf_train$Long)) )

# check Population
# summary(conf_train$Population)
setkeyv(conf_train, c("CountryProv","Date"))


# visually check
# summary(conf_train$ratio_confirmed_total_pct)
# conf_train[conf_train$ratio_confirmed_total_pct > 100, "ratio_confirmed_total_pct"]
stopifnot( all(conf_train$ratio_confirmed_total_pct <= 100, na.rm=T) )
# any(conf_train$ratio_confirmed_total_pct > 100, na.rm=T)


"""## save"""

# save
#stop("uncomment to overwrite")

save_fn = "t11c-confirmed+totalTests-historical.csv"
save_fn = sprintf("%s/%s", dir_gitrepo, save_fn)
# Use na="" since arcgis.com doesn't support values for NAs
# write.csv(conf_train, "t11c-confirmed+totalTests-v20200406-historical.csv")
write.csv(conf_train, save_fn, na="", row.names=F,quote=F)

