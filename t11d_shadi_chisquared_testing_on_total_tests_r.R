# -*- coding: utf-8 -*-
#"""t11d-shadi-chisquared testing on total tests.r.ipynb
#
#Automatically generated by Colaboratory.
#
#Original file is located at
#    https://colab.research.google.com/drive/1bNZDH8Jh-RQEPUXpw6CcLuH1qFSw3AVv
#
#Notebook file requirements:
#
#- `gitlab/biominers/kaggle-w1/ellipse_lib.R`
#- ~~~`covid19-testing-data/l2/historical.csv`~~~
#- `gitlab/biominers/covid19-testing-data/l2/interpolated_by_transformation.csv`
#


## Packages
#"""

#install.packages(c("data.table", "zoo"))# , "caret", "hexbin"))

library(data.table)
library(zoo)

totaltests_fn = "/home/shadi/Development/gitlab.com/biominers/covid19-testing-data/l2-withConfirmed/interpolated_by_transformation.csv"

stopifnot(file.exists(totaltests_fn))
conf_train = read.csv(totaltests_fn, stringsAsFactors=F)
conf_train = conf_train[with(conf_train, order(CountryProv, Date, decreasing = F)), ]
conf_train = data.table(conf_train)


# check negative values in the confirmed cases
#any(conf_train[,"total_cumul.all"] < 0, na.rm=T)

#"""## Create 2 wide matrices for confirmed and totals"""

get_wide <- function(fx, mtx_long) {
    conf_wide = reshape(mtx_long[,c("CountryProv","Date",..fx)],
                        idvar = "CountryProv",
                        timevar = "Date",
                        direction = "wide")
    conf_countryprov = conf_wide$CountryProv
    # conf_wide = conf_wide[, which(colnames(conf_wide)!="CountryProv")]
    # conf_wide = conf_wide[, 2:ncol(conf_wide)] # not sure why the above didnt work
    conf_wide = conf_wide[, -1] # does this work? Yes!
    colnames(conf_wide) = gsub(sprintf("%s.",fx),"",colnames(conf_wide))
    conf_wide = t(conf_wide)
    colnames(conf_wide) = conf_countryprov
    conf_dt = as.Date(rownames(conf_wide))

    list(wide=conf_wide, dt=conf_dt, countryprov=conf_countryprov)
}

# Use the data-cleaned ones (for dips and compared to conf)
#conf_wide = get_wide("ConfirmedCases", conf_train)
conf_wide = get_wide("cases_cumulClean", conf_train)

#tot_wide = get_wide("total_cumul.all", conf_train)
#conf_wide = get_wide("conf_cummax", conf_train) # no need to use this after ConfirmedCases has been corrected
#tot_wide = get_wide("tests_cumulInterpolated", conf_train)
tot_wide = get_wide("tests_cumulNoSpike", conf_train)

# check that all countryprovs match between confirmed data and totals data
stopifnot(all(conf_wide$dt == tot_wide$dt))
stopifnot(all(conf_wide$countryprov == tot_wide$countryprov))

# confirmed cases does not have any country which is completely missing
idx_col = apply(conf_wide$wide, 2, function(x) all(is.na(x)))
stopifnot(!any(idx_col))

# total tests does have countries which are completely missing
idx_col = apply(tot_wide$wide, 2, function(x) all(is.na(x)))
stopifnot(any(idx_col))

# drop countries with no data
tot_wide$wide = tot_wide$wide[,!idx_col]
tot_wide$countryprov = tot_wide$countryprov[!idx_col]
conf_wide$wide = conf_wide$wide[,tot_wide$countryprov]
conf_wide$countryprov = tot_wide$countryprov

# example country with no data that should not be available anymore
stopifnot( ! ("China – Guizhou" %in% tot_wide$countryprov))
stopifnot( ! ("China – Guizhou" %in% conf_wide$countryprov))

# update 2020-05-28 this no longer works
#stopifnot( ! ("France – Saint Barthelemy" %in% tot_wide$countryprov))



# test
y  = tot_wide$wide[,"Afghanistan"]



#"""## Compute daily numbers (i.e. 1st order difference)"""

# calculate daily confirmed cases
# Pay attention to negative values from "wrong" cumulative values
# conf_wide$diff = apply(conf_wide$wide,        2, function(x) c(NA,diff(x)))
conf_wide$diff = apply(conf_wide$wide,        2, function(x) c(0,diff(x)))

# replace negative values with 0's
conf_wide$diff = pmax(conf_wide$diff, 0)

# should not have any na
stopifnot(!any(is.na(conf_wide$diff)))

# replace NA with 0's
#conf_wide$diff = na.fill(conf_wide$diff, 0)
#rownames(conf_wide$diff) = conf_wide$dt

#dim(is.na(conf_wide$diff))
# check na's in tot_wide$interpolated
#idx_row = apply(conf_wide$diff, 1, function(x) any(is.na(x)))
#idx_col = apply(conf_wide$diff, 2, function(x) any(is.na(x)))
#conf_wide$diff[idx_row, idx_col, drop=F]
#conf_wide$wide[idx_row, idx_col, drop=F]
#c(idx_row, idx_col)

# check negative values

# Note that this stopifnot is just a safety switch
# because I already replace negative values with 0 above
# Update: after data cleaning, no need to replace na with 0
stopifnot(all(conf_wide$diff >= 0))



# Use the interpolated for total tests
# Update 2020-05-06: no longer using the interpolated since done in CLI/l2
#tot_wide$diff  = apply(tot_wide$interpolated, 2, function(x) c(NA,diff(x)))
#tot_wide$diff  = apply(tot_wide$interpolated, 2, function(x) c(0,diff(x)))
tot_wide$diff  = apply(tot_wide$wide, 2, function(x) c(0,diff(x)))

# for missing dates, can set to 0, but the minimum is the number of cases
# tot_wide$diff = na.fill(tot_wide$diff, 0)
# tot_wide$diff = na.fill(tot_wide$diff, conf_wide$diff)
# tot_wide$diff[is.na(tot_wide$diff)] = conf_wide$diff[is.na(tot_wide$diff)]

# after using interpolated data, should not have any NA
# Update 2020-05-06: will be left with trailing NA's only
#stopifnot(!any(is.na(tot_wide$diff)))
stopifnot(any(is.na(tot_wide$diff)))

# also should not have negative values for total tests if interpolation was done right
stopifnot(!any(tot_wide$diff<0, na.rm=T))


# find points where total tests < number of cases
#
negmat = tot_wide$diff - conf_wide$diff

# as of 2020-04-30 16:28 .. -198507
# as of 2020-04-30 17:30 .. -131607 .. after first batch of fixes
# as of 2020-05-06 16:38 .. -114390 .. after conf.cummax and tests.interpolate_by_transformation
# as of 2020-05-07 12:03 .. -121461 .. after manual fixing of confirmed, only negatives left from ffill
# as of 2020-05-07 12:03 .. 0 .. keeping negatives at NA and dropping ffill => no more negatives!
print("sum negatives: test - conf daily = ")
print(sum(negmat[negmat<0], na.rm=T))

# check na's in tot_wide$interpolated
idx_row = apply(negmat, 1, function(x) any(x < -1e3, na.rm=T))
idx_col = apply(negmat, 2, function(x) any(x < -1e3, na.rm=T))
negmat[idx_row, idx_col, drop=F]

# should not have any total tests < number of cases
# Update 2020-05-07: after the spike fixing, introduced some negatives, eg mexico and nebraska
#stopifnot(all(tot_wide$diff >= conf_wide$diff, na.rm=T))
# Update 2020-06-04: change frmo 11 to 12
# Update 2020-06-10: change to < 100 (eventhough exact value is 100)
print(sum(tot_wide$diff < conf_wide$diff, na.rm=T))
stopifnot(sum(tot_wide$diff < conf_wide$diff, na.rm=T) < 100) # the complement is 31417

# finally, setting the total tests to the number of cases as a minimum
# tot_wide$diff = pmax(tot_wide$diff, conf_wide$diff)

#tot_wide$diff[,"Colombia"]
#tot_wide$interpolated[,"Azerbaijan",drop=T]

idx_row = apply(tot_wide$diff, 1, function(x) any(x < -10, na.rm=T))
idx_col = apply(tot_wide$diff, 2, function(x) any(x < -10, na.rm=T))
#idx_row = apply(tot_wide$diff, 1, function(x) any(is.na(x)))
#idx_col = apply(tot_wide$diff, 2, function(x) any(is.na(x)))
tot_wide$diff[idx_row, idx_col, drop=F]


#"""## Compute moving sum of x days"""

#nday_sum2 = 7

# Update 2020-04-16: making this a 2-sided window
# Update 2020-05-06: back to single-sided
#moving_sum <- function(x,n=5){filter(x,rep(1/n,  n), sides=1)} 
#moving_sum <- function(x,n=5){filter(x,rep(1,  n), sides=2)} 
moving_sum <- function(x,n=5){filter(x,rep(1,  n), sides=1)} 

conf_wide$mvsum_03 = apply(conf_wide$diff, 2, function(x) moving_sum(x, 7))
tot_wide$mvsum_03  = apply(tot_wide$diff , 2, function(x) moving_sum(x, 7))

conf_wide$mvsum_07 = apply(conf_wide$diff, 2, function(x) moving_sum(x,14))
tot_wide$mvsum_07  = apply(tot_wide$diff , 2, function(x) moving_sum(x,14))


# found negatives? (check below "France – Saint Barthelemy" as of apr 15)
# stop("got some 'negative' moving sum, eg Armenia")
stopifnot( all(tot_wide$mvsum_07 >= 0, na.rm=T) )


#"""Go back from wide matrices to a single long matrix with all the relevant fields"""

get_long <- function(mtx_wide, fx) {
  temp_wide = data.table(mtx_wide)
  temp_wide$Date = conf_wide$dt
  df_long <- melt(setDT(temp_wide), id.vars = c("Date"), variable.name = "CountryProv")
  colnames(df_long)[colnames(df_long)=="value"] = fx
  df_long
}

# 3-day sum versus 7-day sum
totals_dayPairs = merge(
    merge( get_long(conf_wide$mvsum_03,   "case_d2"),
          get_long(tot_wide$mvsum_03 ,   "both_d2"),
          all.x=T, all.y=T, sort=F),
    merge( get_long(conf_wide$mvsum_07,  "total_case"),
          get_long(tot_wide$mvsum_07 ,  "total_both"),
          all.x=T, all.y=T, sort=F),
    all.x=T, all.y=T, sort=F
  )


# calculate missing variables
totals_dayPairs$total_control = with(totals_dayPairs, total_both-total_case)
totals_dayPairs$control_d2 = with(totals_dayPairs, both_d2-case_d2)

setkeyv(totals_dayPairs,c("CountryProv","Date"))

#"""## Compute sufficiency of tests per country
#
#Refer to code in notebook `t7e`
#
#Manually upload `ellipse_lib.R` from the gitlab repo `kaggle-covid19-global-forecasting-week-1`
#"""

source("/home/shadi/Development/gitlab.com/biominers/kaggle-covid19-global-forecasting-week-1/shadi/ellipse_lib.R")

#"""Build thresholds per row (takes ~3 mins on colab as of 2020-05-06)"""

# row number in totals_dayPairs
ndays = nrow(totals_dayPairs)
skip_row = c()

# initialize columns for threshold_min and threshold_max
# Use 0 first to get doubles, then use NA
# Otherwise, will get logicals matrix
totals_dayPairs$threshold_min = 0
totals_dayPairs$threshold_min = NA
totals_dayPairs$threshold_max = 0
totals_dayPairs$threshold_max = NA

# iterate over all days
for(i in 1:ndays) {

    if(i%%1e3==0) {
      print(sprintf("Row %i/%i: Skipped %s rows so far.", i, ndays, length(skip_row)))
      flush.console()
    }

    if(is.na(as.numeric(totals_dayPairs[i,"total_case"]))    |
       is.na(as.numeric(totals_dayPairs[i,"total_control"])) |
       (as.numeric(totals_dayPairs[i,"total_case"])<=0)      | 
       (as.numeric(totals_dayPairs[i,"total_control"])<=0)     ) {
      # print(sprintf("Skip entry %i",i))
      # flush.console()
      skip_row = c(skip_row, i)
      next
    }

    if(totals_dayPairs[i,"control_d2"]==totals_dayPairs[i,"total_both"]) {
      # This is the extremity of the ellipse, so just take a shortcut
      totals_dayPairs[i,"threshold_min"] = totals_dayPairs[i,"control_d2"]
      totals_dayPairs[i,"threshold_max"] = totals_dayPairs[i,"control_d2"]
      next
    }

    # Control the thresholds width with this p-value
    # Make this smaller to make thresholds wider
    # pvalue = 5e-7
    # Use 5e-2 and adjust it for the number of tests
    # (i.e. 60 days of data since I'm doing pairs fo days)
    # TODO: should divide p-value by ndays?
    pvalue = 5e-2 # /ndays

    ellipse_out <- perform.ellipse(NULL, pvalue,
                                  c( as.numeric(totals_dayPairs[i,"total_control"]),
                                      as.numeric(totals_dayPairs[i,"total_case"])
                                    )
                                  )

    thres_min_max = get.ellipse.coord(ellipse_out, x=as.numeric(totals_dayPairs[i,"control_d2"]))
    totals_dayPairs[i,"threshold_min"] = min(thres_min_max)
    totals_dayPairs[i,"threshold_max"] = max(thres_min_max)

}

# Update 2020-03-29: actually, better keep the 0's
# idx_tona = totals_dayPairs$threshold_min==0 & totals_dayPairs$threshold_max==0
# totals_dayPairs$threshold_min[idx_tona] = NA
# totals_dayPairs$threshold_max[idx_tona] = NA

totals_dayPairs$outside = with(totals_dayPairs, case_d2<threshold_min | case_d2>threshold_max)

# ellipse_out
#totals_dayPairs[i,]

# calculate distance from case_d2 to threshold_max or threshold_min
# totals_dayPairs$case_excess= NULL
totals_dayPairs$cased2_excess = with( totals_dayPairs,
                                      ifelse( case_d2>=threshold_min & case_d2<=threshold_max,
                                              0,
                                              pmin(abs(case_d2-threshold_min), abs(case_d2-threshold_max))
                                          )
                                      )

#"""## Plots
#
#Plot 1: raw
#"""

dtvec = tot_wide$dt

# start debug: why sum threshold_min is giving a bump at feb

#plot(dtvec, conf_wide$wide[,"Austria"])
#grid()
#plot(dtvec, tot_wide$wide[,"Austria"])
#grid()
thmin_wide = get_wide("threshold_min", totals_dayPairs)


df1 = thmin_wide$wide

library(zoo)



#"""## Pick last date and check if over-testing or under-testing"""

totals_dayPairs$Date = totals_dayPairs$Date
keep_wide = get_wide("outside", totals_dayPairs)

# last_keep = tail(keep_wide$wide,1)

# after 2-sided average, need to take T-4
last_keep = head(tail(keep_wide$wide,4),1)

last_keep = as.character(last_keep)
last_keep[is.na(last_keep)] = 'NA'

#last_keep = tail(keep_wide$wide,1)

# after 2-sided average, need to take T-4
last_keep = head(tail(keep_wide$wide,4),1)

last_keep = t(last_keep)

# perform binomial test on lebanon
# https://en.wikipedia.org/wiki/Binomial_test ######### <<<<<<<<<
# https://en.wikipedia.org/wiki/Binomial_distribution
# https://www.stat.berkeley.edu/~stark/SticiGui/Text/chiSquare.htm
# TODO
# binom.test(51, 235, (1/6), alternative = "two.sided") (two-tailed test)

#"""## instead of just last date, count last 10 days
#
#and require 5 out of 10 to be inside thresholds
#"""

excess_wide = get_wide("cased2_excess", totals_dayPairs)

max_excess = ceiling(max(totals_dayPairs$cased2_excess, na.rm=T)/1e4)*1e4

last_keep = tail(excess_wide$wide,10)

# sum then reverse (i.e. countries with bigger numbers have more points inside the thresholds)
#last_keep = apply(last_keep, 2, function(x) sum(1-x,na.rm=T))
#last_keep = as.character(last_keep)

# when using excess, just sum for the maximum excess, and multiply by -1 for maintaining bigger numbers being better
last_keep = apply(last_keep, 2, function(x) sum(max_excess-x,na.rm=T))

# count number of NA
count_na = apply(   tail(excess_wide$wide,10),
                    2,
                    function(x) sum(is.na(x))
                  )

# calculate max confirmed cases over this last 10 days
# This helps to cut some slack to countries with much more cases
# if it shows that they have insufficient testing
max_confirmed = apply(tail(conf_wide$wide,10), 2, function(x) max(x, na.rm=T))

# also the max new-cases
max_newconf = apply(tail(conf_wide$diff,10), 2, function(x) max(x, na.rm=T))

#useless with na.rm=T#last_keep[is.na(last_keep)] = 'NA'
last_keep = data.table(
              cased2_excess = last_keep,
              CountryProv = colnames(excess_wide$wide),
              count_na=count_na,
              max_confirmed=max_confirmed,
              max_newconf=max_newconf
            )
last_keep$rank_sufficientTesting = frank(last_keep, -cased2_excess, CountryProv)
setkeyv(last_keep, "CountryProv")



#"""## Global plot of positives to tests"""

v_num = apply(conf_wide$wide, 1, function(x) sum(x, na.rm=T))
v_den = apply(tot_wide$wide , 1, function(x) sum(x, na.rm=T))

# drop first few points
v_num = v_num[5:length(v_num)]
v_den = v_den[5:length(v_den)]


# average of ratios of each country
v_gl = apply(conf_wide$wide/tot_wide$wide*100, 1, function(x) mean(x, na.rm=T))


#"""## filter for countries/dates where daily confirmed cases increased/decreased while daily cases </> threshold
#
#This shows when the threshold-mid is useful. It also happens when cases increases due to testing increase.
#
#eg for Florida, it didnt prove any use
#"""

#tail(totals_dayPairs["Austria"])
#mydiff2 <- function(x) diff(diff(x, lag=2, differences=1), lag=1, differences=1)

# calculate 7-day sum (same as diff_7 on cumulative)
mydiff2 <- function(x) diff(diff(x, lag=7, differences=1), lag=1, differences=1)

conf_wide$diff2_07 = apply( conf_wide$wide,
                            2,
                            function(x) {
                              o=c(rep(0,8),mydiff2(x))
                              names(o)=conf_wide$dt # [(7:length(conf_wide$dt)]
                              o
                            })

# cased2_excess was unsigned, so need a new signed distance
totals_dayPairs$cased2_excSigned = with( totals_dayPairs,
                                      ifelse( case_d2>=threshold_min & case_d2<=threshold_max,
                                              0,
                                              ifelse( case_d2 < threshold_min,
                                                case_d2-threshold_min,
                                                case_d2-threshold_max
                                              )
                                          )
                                      )

cased2_exc = get_wide("cased2_excSigned", totals_dayPairs)

#cased2_exc$diff = NULL
cased2_exc$diff2_07 = apply(cased2_exc$wide,        
                        2, 
                        function(x) { o=c(0,diff(x)); names(o)=cased2_exc$dt; o })

cases_d2 = merge(
    merge( get_long(conf_wide$wide, "cumul_conf"),
           get_long(conf_wide$diff ,   "daily_conf"),
           all.x=T, all.y=T, sort=F),
    merge( get_long(conf_wide$diff2_07,  "diff2_07_conf"),
           get_long(cased2_exc$diff2_07 ,  "diff2_07_excess"),
           all.x=T, all.y=T, sort=F),
    all.x=T, all.y=T, sort=F
  )

cases_d2 = merge(
    cases_d2,
    merge(  get_long(tot_wide$wide, "cumul_tests"),
            get_long(tot_wide$diff ,   "daily_tests"),
            all.x=T, all.y=T, sort=F),
    all.x=T, all.y=T, sort=F
  )

  tail(cases_d2)

# cases_d2["is_diff"] = with(cases_d2, (sign(diff2)!=sign(thres_exc)) & (sign(diff2)!=0) & (0!=sign(thres_exc)))
cases_d2[,"is_diff"] = with(cases_d2, sign(diff2_07_conf)*sign(diff2_07_excess)==-1)
cases_d2$is_diff[is.na(cases_d2$is_diff)] = F

setkeyv(cases_d2, c("CountryProv","Date"))


#"""## Vietnam as an example"""

df_plot = cases_d2["Vietnam"]

#df_plot[df_plot$is_diff]
w_ctx = filter(df_plot$is_diff,c(1,1,1,1,1), sides=2)>=1
w_ctx[is.na(w_ctx)]=F


#"""## Merge fields for final datatable and save for dashboard"""

cases_d2 = merge(cases_d2,
      totals_dayPairs[, c("CountryProv", "Date", "control_d2", "case_d2", "threshold_min", "threshold_max")],
      all.x=T, all.y=F, by=c("CountryProv", "Date")
)

#setkeyv(df_incdec, c("CountryProv", "Date"))

cases_d2$diff2_07_tests = c(0, diff(cases_d2$control_d2))

#stop("uncomment and update date field")
write.csv(cases_d2, "/home/shadi/Development/gitlab.com/biominers/covid19-testing-data/l4-analysis/t11d-chisquared-history-v20200512.csv", row.names=F, na='')

